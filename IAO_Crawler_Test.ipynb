{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import logging\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "\n",
    "#custom spider to crawl IAO website\n",
    "class IAOCrawler(scrapy.Spider):\n",
    "    name = \"IAO Blog-Crawler\"\n",
    "    start_urls = [\n",
    "        'https://blog.iao.fraunhofer.de/',\n",
    "    ]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'FEEDS' : {\n",
    "            'results.json': {\n",
    "                'format': 'json',\n",
    "                'overwrite': True,\n",
    "                'encoding': 'utf-8'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    #yields data of individual blog-posts\n",
    "    def parse(self, response):\n",
    "        containers = response.css('div.entry-container')\n",
    "        for entry in containers:\n",
    "            yield {\n",
    "                'titel': entry.xpath('.//header/h2/span/a/text()').get(),\n",
    "                'date': entry.css('time.entry-date::text').get(),\n",
    "                'author': entry.xpath('.//span[@class=\"author\"]/a/text()').get(),\n",
    "                'author_link': entry.xpath('.//a[@class=\"entry-author-link\"]').attrib['href'],\n",
    "                'series': entry.xpath('.//div//b/text()').get(default=\"none\"),\n",
    "                'comments': entry.xpath('//span[@class=\"comments-link\"]/a/@href').get(\"comments disabled\"),\n",
    "            }\n",
    "        \n",
    "        #creates a http request, loading the next page\n",
    "        next_page = response.xpath('.//div[@id=\"next-posts\"]/a').attrib['href']\n",
    "        print(\"scraping:\" + next_page)\n",
    "        yield scrapy.Request(next_page)\n",
    "    \n",
    "        \n",
    "\n",
    "def run():\n",
    "    crawler = CrawlerRunner()\n",
    "    return crawler.crawl(IAOCrawler)\n",
    "\n",
    "#runs the crawler\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
